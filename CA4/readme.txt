We came in from CA4 only missing a few tests, and were already reasonably faster than the optimized reference compiler. Strangely, those few tests we were missing were fixed by implementing more optimizing features. Our main additions were: more rigorous Int/Bool unboxing, switching to 32bit arithmetic, some minor peephole optimizations, improvements to our calling convention, rewriting of our internals, and data-flow analysis.

Unboxing was improved so that Ints and Bools were only boxed when necessary. We managed to reduce this to case expressions, assignment into variables of type Object, and branch merges (with ifs or cases) where the least upper bound was Object. All other instances, including function parameters, local variables, and object attributes, were left unboxed. We implemented the unboxing by adding a flag to our virtual register objects indicating whether the value was boxed or unboxed, and essentially pulled values out of their containing objects wherever possible. Inconsistencies with unboxing turned out to be the source of most of our errors. At one point a new error showed up in the middle of implementing the extended unboxing, and it was strange to discover that the solution was to keep going rather than fixing something that was already written.

Our arithmetic for CA4 involved some strange bit shifting to get 64bit instructions to match the function of 32bit instructions. This led to three assembly instructions for what should have been one on each arithmetic operation. We fixed this flaw by switching to 32bit instructions, adding some extra logic to handle using the appropriate size register for each instruction.

Our peephole optimizations focused on eliminating some dumb code patterns that showed up in the translation from TAC to assembly that we could not really eliminate any other way. One of the bigger ones was an "if (a < b)" condition check taking six instructions rather than the required two. Reducing that case should have improved loop performance, and showed a small increase in speed.

We improved our calling convention to match the c calling convention. Our easy-to-implement convention was that everything gets passed on the stack, and all registers are callee save. We modified our register allocation to have conflicts with the caller save registers on virtual registers that were live during a function call. We also changed our references to parameters to resolve to the appropriate registers first before going to the stack. By matching the c calling convention, we were able to directly use assembly code generated by gcc from c code for our internals (before we had to modify the assembly to follow our calling convention), which made rewriting our internals much easier. It also allowed us to use heavier optimization from gcc on our internals code as we no longer needed to be able to read the assembly.

It seems that loading libraries takes far longer than expected. By doing some profiling, we discovered that the first call to a function from a library (e.g. from including strings.h for strlen or stdlib.h for malloc) took around 50% of the program's runtime, presumably looking up or loading the shared library code. By rewriting our internals to minimize the number of libraries used, we cut our average runtime in half (from ~50% to ~30%). The major removals were string utility functions and malloc. String utility functions were simply inlined wherever they occurred, and malloc was replaced with a custom memory management function. The custom memory management used sbrk, a wrapper around a system call that claims memory (still technically a library function, but for some reason takes less time to load), to allocate large blocks that were then filled in order whenever memory was needed.

Our data-flow analysis implementation used a lattice with three levels, with the middle holding a range of possible values for integers, the value of Bools, and an isvoid flag for Objects. We then used this information to eliminate unnecessary branches.

We ended up with about twenty more tests for CA5, and included some of the more interesting tests. The first test is what reproduced most of the bugs we were seeing on the test server but were having trouble finding on our own. Many of the issues involved Int function parameters being unboxed, but local variables being boxed, causing strange things when parameters were re-assigned to. The second test is what we imaging the mat5 test from the server looks like, written becuase it was one of our last failing tests and we thought it might be useful for benchmarking. It didn't reproduce the error we were seeing, but it was useful for finding inefficiencies. The third test is a simple test meant to stress case statements. The fourth test is a very large object meant to stress our memory management.

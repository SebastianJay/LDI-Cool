We came in from CA4 only missing a few tests, and were already reasonbly faster than the optimized reference compiler. Strangely, those few tests we were missing were fixed by implementing more optimizing features. Our main additions were: more rigorous Int/Bool unboxing, switching to 32bit arithmetic, some minor peephole optimizations, improvements to our calling convention, rewriting of our internals, and data-flow analysis.

Unboxing was improved so that Ints and Bools were only boxed when necessary. We managed to reduce this to case expressions, assignment into variables of type Object, and branch merges (with ifs or cases) where the least upper bound was Object. All other instances, including function parameters, local variables, and object attributes, were left unboxed. We implemented the unboxing by adding a flag to our virtual register objects indicating whether the value was boxed or unboxed, and essentially pulled values out of their containing objects wherever possible. Inconsistencies with unboxing turned out to be the source of most of our errors. At one point a new error showed up in the middle of implementing the extended unboxing, and it was strange to discover that the solution was to keep going rather than fixing something that was already written.

## 32bit arith

Our peephole optimizations focused on eliminating some dumb code patterns that showed up in the translation from TAC to assembly that we could not really eliminate any other way. One of the bigger ones was an "if (a < b)" condition check taking six instructions rather than the reqired two. Reducing that case should have improved loop performance, and showed a small increase in speed.

We improved our calling convention to match the c calling convention. Our easy-to-implement convention was that everything gets passed on the stack, and all registers are callee save. We modified our register allocation to have conflicts with the caller save registers on virtual registers that were live during a function call. We also changed our references to parameters to resolve to the appropriate registers first before going to the stack. By matching the c calling convention, we were able to directly use assembly code generated by gcc from c code for our internals (before we had to modify the assembly to follow our calling convention), which made rewriting our internals much easier. It also allowed us to use heavier optimization from gcc on our internals code as we no longer needed to be able to read the assembly.

It seems that loading libraries takes far longer than expected. By doing some profiling, we discovered that the first call to a function from a library (e.g. from including strings.h for strlen or stdlib.h for malloc) took around 50% of the program's runtime, presumably looking up or loading the shared library code. By rewriting our internals to minimize the number of libraries used, we cut our average runtime in half (from ~50% to ~30%). The major removals were string utility functions and malloc. String utility functions were simply inlined wherever they occured, and malloc was replaced with a custom memory management function. The custom memory management used sbrk, a wrapper around a system call that claims memory (still technically a library function, but for some reason takes less time to load), to allocate large blocks that were then filled in order whenever memory was needed.

## data-flow

## Tests

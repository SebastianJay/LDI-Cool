There were two phases to this project: the first was deserializing the .cl-ast format into a tree structure, and the second was traversing through that tree and generating a sequence of three address code instructions. We used our code from the previous assignment to serialize the instruction list back to .cl-tac.

In hindsight, our code for serializing and deserializing an abstract syntax tree was rather verbose, but we were able to use it for both CA2 and PA3 which saved time on debugging and rewriting common code. Our implementation used a set of objects representing types of nodes in the AST with fields holding the children of that node. Our root was an AST object which held a list of ASTClass objects and so on. This structure allowed us to build the tree using simple constructors that took arguments from the ply rules, and a simple (to use) recursive load method that deserialized the tree from the lines of a file. The most complicated part of the code was the ASTExpression class which dealt with all the different types of expressions. We could have implemented expressions using a polymorphic structure, but that would have made the code even more verbose than it already was. Instead, we indicated the type of expression with a string field, and stored the varying sub-parts of each expression in a general "args" field which made use of Python's dynamic typing. Our load method for expressions used a large if-else tree to handle the many types of expressions (grouping expressions with similar arguments together to use the same code), and during parsing we simply fed the appropriate tuple of objects to the constructor. Serializing the tree used an overridden __str__ method that followed the rules from the assignment specification. This let us serialize the tree by simply calling str(ast).

With the tree deserialized, we implemented TAC generation by traversing the tree and following a "recipe" of instruction emissions at each node -- with an imperative language like Python, this was relatively easy. Because our test cases were restricted to just one method, we went down the tree to find the first method of the first class. We generated instructions for copying method arguments into registers, and we then began a trace of function calls for the method body, which contained an expression.

To generate TAC for an expression node, we first checked its type. Depending on what it was, we emitted certain instructions, possibly calling the generation function on child expression nodes. For "if" and "while", we emitted labels, branches, and jumps to evaluate a predicate and execute a body, each of which was recursively generated. For "let", we pushed a mapping from identifier to register into a symbol table before recursing on the expression child node. Logic for the other types of AST nodes was pretty straightforward. When the code generation for a node was complete, the register containing the result of the expression was returned (so it could then be used by the parent node). When the top level expression was complete, its result became the return value of the method.

Overall, the process was simple, but there were a few specific points to note. First, our symbol table contained a mapping from an identifier to a stack of registers, the intuition being that the same identifier could be bound multiple times in a chain of "let" statements -- when one "let" began, we would push a mapping, and when it exited, we would pop it (demonstrated in test1.cl). Second, since "while" did not have a formal return value, its TAC recipe generated a default Object in its return register, possibly creating dead assignments (demonstrated in test2.cl). Lastly, we used a static class to manage data that was "global" among function calls, like label and register counters as well as the symbol table.

One final note: there were a couple of expression types that were left unimplemented because they were outside of the scope of the assignment: static dispatch, dynamic dispatch, and case statements. We allowed for self dispatch so that calls to I/O would work.
